Modern generative models are sophisticated enough to produce fake\footnote{We
use the term fake to refer to computer generated samples} speech samples that
can be indistinguishable from real human speech. In this section, we provide a
summary of some existing neural speech synthesis models and their architectures.

WaveNet~\cite{van2016wavenet} is a generative neural network that is trained
end-to-end to model quantized audio waveforms. The model is fully probabilistic
and autoregressive, using a stack of causal convolutional layers to condition
the predictive distribution for each audio sample on all previous ones. It has
produced impressive results for generation of speech audio conditioned on
speaker and text and has become a standard baseline for neural speech generative
models. 

SampleRNN~\cite{mehri2016samplernn} is another autoregressive architecture that
has been successfully used to generate both speech and music samples. SampleRNN
uses a hierarchical structure of deep RNNs to model dependencies in the sample
sequence. Each deep RNN operates at a different temporal resolution so as to
model both long term and short term dependencies. 

Recent work on deep learning architectures has also introduced the presence of
\textit{adversarial examples}: small perturbations to the original inputs,
normally imperceptible to humans, which nevertheless cause the architecture to
generate an incorrect or deliberately chosen output. In their brilliant papers,
~\cite{szegedy2013intriguing} and ~\cite{goodfellow2014explaining} analyze the
origin of adversarial attacks and describe simple and very efficient techniques
for creating such perturbations, such as the fast gradient sign method (FGSM). 

In the vision domain, ~\cite{sharif2016accessorize} describe a technique for
attacking facial recognition systems. Their attacks are physically realizable
and inconspicuous, allowing an attacker to impersonate another individual. In
the speech domain,~\cite{carlini2016hidden} describe attacks on
speech-recognition systems which use sounds that are hard to recognize by humans
but interpreted as specific commands by speech-recognition systems.

To the best of our knowledge, GANs have not been used for the purpose of speech
synthesis\footnote{More specifically, Mel-Spectrogram synthesis}.
\cite{pascual2017segan} uses a conditional GAN for the purpose of speech
\textit{enhancement}, i.e. taking as input a raw speech signal and outputting a
denoised waveform. The model in \cite{chang2017learning} tackles the reverse
problem of using GANs to learn certain representations given a speech
spectrogram.
