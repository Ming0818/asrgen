Speaker recognition and authentication systems are being deployed for security
critical applications such as banking, forensics, home automation, etc. Like
other domains, these systems benefit from recent advancements in deep
learning that lead to improved accuracy and trainability of such systems.
Despite the improvement in the efficiency of these systems, evidence shows that
they can be suspectible to adversarial attacks\cite{wu2015spoofing}, thus motivating a current trend
focused understanding adversarial attacks (\cite{szegedy2013intriguing}, \cite{goodfellow2014explaining}) and finding countermeasures to detect of deflect them. 

Parallel to these advancements, neural speech \textit{generation} (the process of using deep neural networks to generate human-sounding speech) has also seen huge progress (\cite{wang2017tacotron}, \cite{arik2017deep}). Generative Adversarial Networks (GANs) have recently been found to produce incredibly  authentic samples in a variety of fields. The core idea of GANs - namely the minimax game played between a generator network and a discriminator network - extends very naturally to the field of speaker authentication and spoofing. \\
The combination of these advancements begs a natural question that has, to the
best of our knowledge, not been answered:
\begin{center}
Are state-of-the-art speech recognition systems robust \\to adversarial attacks by speech generative models?
\end{center}

More specifically, we contemplate this question and offer in this paper the following contributions:
\begin{itemize}
\item We evaluate SampleRNN and WaveNet in their ability to fool text-independent state-of-the-art speaker recognizers.
\item We propose strategies for untargeted attacks using Generative Adversarial Networks.
\item We propose strategies for targeted attacks using a new objective function based on the improved Wasserstein GAN.
\end{itemize}
